{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fd72398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# âœ… 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_review = pd.read_json(\"data/review_0503.json\", lines=True)\n",
    "df_user = pd.read_json(\"data/user_0503.json\", lines=True)\n",
    "df_biz = pd.read_json(\"data/business.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e625bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š [ê²°ì¸¡ì¹˜ ìˆëŠ” ì»¬ëŸ¼]\n",
      "user_name         272580\n",
      "review_count_x    272580\n",
      "useful_y          272580\n",
      "average_stars     272580\n",
      "dtype: int64\n",
      "\n",
      "âœ… ë³‘í•©ëœ ë°ì´í„° ìˆ˜: 676,701ê°œ\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 676701 entries, 0 to 676700\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   review_id       676701 non-null  object        \n",
      " 1   user_id         676701 non-null  object        \n",
      " 2   business_id     676701 non-null  object        \n",
      " 3   stars_x         676701 non-null  int64         \n",
      " 4   useful_x        676701 non-null  int64         \n",
      " 5   date            676701 non-null  datetime64[ns]\n",
      " 6   sentiment       676701 non-null  object        \n",
      " 7   cleaned_text    676701 non-null  object        \n",
      " 8   token_length    676701 non-null  int64         \n",
      " 9   user_name       404121 non-null  object        \n",
      " 10  review_count_x  404121 non-null  float64       \n",
      " 11  useful_y        404121 non-null  float64       \n",
      " 12  average_stars   404121 non-null  float64       \n",
      " 13  business_name   676701 non-null  object        \n",
      " 14  address         676701 non-null  object        \n",
      " 15  city            676701 non-null  object        \n",
      " 16  state           676701 non-null  object        \n",
      " 17  stars_y         676701 non-null  float64       \n",
      " 18  review_count_y  676701 non-null  int64         \n",
      " 19  is_open         676701 non-null  int64         \n",
      " 20  categories      676701 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(5), object(11)\n",
      "memory usage: 108.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_review = pd.read_json(\"data/review_0503.json\", lines=True)\n",
    "df_user = pd.read_json(\"data/user_0503.json\", lines=True)\n",
    "df_biz = pd.read_json(\"data/business.json\", lines=True)\n",
    "\n",
    "# 2. ì»¬ëŸ¼ëª… ì¶©ëŒ ë°©ì§€\n",
    "df_user = df_user.rename(columns={\"name\": \"user_name\"})\n",
    "df_biz = df_biz.rename(columns={\"name\": \"business_name\"})\n",
    "\n",
    "# 3. ì‚¬ìš©ì ì •ë³´ ë³‘í•©\n",
    "df_merged = df_review.merge(df_user, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# 4. ìŒì‹ì  ì •ë³´ ë³‘í•©\n",
    "df_merged = df_merged.merge(df_biz, on=\"business_id\", how=\"left\")\n",
    "\n",
    "# 5. ê²°ì¸¡ì¹˜ ê°œìˆ˜ ì¶œë ¥\n",
    "na_count = df_merged.isna().sum()\n",
    "na_cols = na_count[na_count > 0]\n",
    "print(\"ğŸ“Š [ê²°ì¸¡ì¹˜ ìˆëŠ” ì»¬ëŸ¼]\")\n",
    "print(na_cols.sort_values(ascending=False))\n",
    "\n",
    "# 6. ë³‘í•© ì™„ë£Œ ì •ë³´\n",
    "print(f\"\\nâœ… ë³‘í•©ëœ ë°ì´í„° ìˆ˜: {len(df_merged):,}ê°œ\")\n",
    "print(df_merged.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a83e308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user_id  stars_x  user_mean   z_score  sentiment_score\n",
      "0  _7bHUi9Uuf5__HHc_Q8guQ        5   5.000000  0.000000                1\n",
      "1  eUta8W_HdHMXPzLBBZhL1A        1   1.000000  0.000000                1\n",
      "2  smOvOajNG0lS4Pq7d8g4JQ        4   3.421053  0.523441                2\n",
      "3  Dd1jQj7S-BFGqRbApFzCFw        5   5.000000  0.000000                1\n",
      "4  IQsF3Rc6IgCzjVV9DE8KXg        5   3.388060  1.381070                2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. ì‚¬ìš©ìë³„ í‰ê· , í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "user_stats = df_merged.groupby(\"user_id\")[\"stars_x\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "user_stats.columns = [\"user_id\", \"user_mean\", \"user_std\"]\n",
    "user_stats[\"user_std\"] = user_stats[\"user_std\"].fillna(0.001)  # std=0 ë°©ì§€\n",
    "\n",
    "# 2. ë‹¤ì‹œ ë³‘í•©\n",
    "df_merged = df_merged.merge(user_stats, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# 3. z-score ê³„ì‚°\n",
    "df_merged[\"z_score\"] = (df_merged[\"stars_x\"] - df_merged[\"user_mean\"]) / df_merged[\"user_std\"]\n",
    "\n",
    "# 4. ê°ì„± ì ìˆ˜ ìƒì„± í•¨ìˆ˜\n",
    "def score_from_z(z):\n",
    "    if z > 0.5:\n",
    "        return 2  # ê¸ì •\n",
    "    elif z < -0.5:\n",
    "        return 0  # ë¶€ì •\n",
    "    else:\n",
    "        return 1  # ì¤‘ë¦½\n",
    "\n",
    "df_merged[\"sentiment_score\"] = df_merged[\"z_score\"].apply(score_from_z)\n",
    "\n",
    "# 5. í™•ì¸\n",
    "print(df_merged[[\"user_id\", \"stars_x\", \"user_mean\", \"z_score\", \"sentiment_score\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a898c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ ê²°ì¸¡ì¹˜ ì œê±° í›„ ë‚¨ì€ í–‰ ìˆ˜: 397,082ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¥ ëª¨ë“  ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” í–‰ ì œê±°\n",
    "df_clean = df_merged.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"ğŸ§¹ ê²°ì¸¡ì¹˜ ì œê±° í›„ ë‚¨ì€ í–‰ ìˆ˜: {len(df_clean):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4ec3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.rename(columns={\n",
    "    \"stars_x\": \"user_rating\",            # ì‚¬ìš©ìê°€ ì¤€ í‰ì \n",
    "    \"useful_x\": \"review_useful\",         # ë¦¬ë·°ì— ëŒ€í•œ ìœ ìš© íˆ¬í‘œ ìˆ˜\n",
    "    \"review_count_x\": \"user_review_count\",  # ì‚¬ìš©ì ì´ ë¦¬ë·° ìˆ˜\n",
    "    \"useful_y\": \"user_total_useful\",     # ì‚¬ìš©ìê°€ ë°›ì€ ìœ ìš© íˆ¬í‘œ ì´í•©\n",
    "    \"stars_y\": \"business_avg_rating\",    # ìŒì‹ì  í‰ê·  í‰ì \n",
    "    \"review_count_y\": \"business_review_count\",  # ìŒì‹ì  ë¦¬ë·° ìˆ˜\n",
    "    \"stars_y\": \"business_avg_rating\",    # ìŒì‹ì  í‰ì \n",
    "    \"z_score\": \"user_rating_zscore\",     # ì‚¬ìš©ì ê¸°ì¤€ í‰ì  í‘œì¤€í™”\n",
    "    \"sentiment_score\": \"sentiment_label\" # 0=ë¶€ì •, 1=ì¤‘ë¦½, 2=ê¸ì •\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "821e012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# addressê°€ ë„ˆë¬´ ì§§ì€ ê²½ìš°, NaNìœ¼ë¡œ ì²˜ë¦¬ (ì˜ˆ: len <= 3)\n",
    "df_clean.loc[df_clean[\"address\"].str.len() <= 3, \"address\"] = pd.NA\n",
    "\n",
    "# ê·¸ëŸ° ë‹¤ìŒ ì™„ì „ ê²°ì¸¡ì¹˜ ì œê±° (ì„ íƒì )\n",
    "df_clean = df_clean.dropna(subset=[\"address\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9fd2bc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396098 entries, 0 to 396097\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   review_id              396098 non-null  object        \n",
      " 1   user_id                396098 non-null  object        \n",
      " 2   business_id            396098 non-null  object        \n",
      " 3   user_rating            396098 non-null  int64         \n",
      " 4   review_useful          396098 non-null  int64         \n",
      " 5   date                   396098 non-null  datetime64[ns]\n",
      " 6   sentiment              396098 non-null  object        \n",
      " 7   cleaned_text           396098 non-null  object        \n",
      " 8   token_length           396098 non-null  int64         \n",
      " 9   user_name              396098 non-null  object        \n",
      " 10  user_review_count      396098 non-null  float64       \n",
      " 11  user_total_useful      396098 non-null  float64       \n",
      " 12  average_stars          396098 non-null  float64       \n",
      " 13  business_name          396098 non-null  object        \n",
      " 14  address                396098 non-null  object        \n",
      " 15  city                   396098 non-null  object        \n",
      " 16  state                  396098 non-null  object        \n",
      " 17  business_avg_rating    396098 non-null  float64       \n",
      " 18  business_review_count  396098 non-null  int64         \n",
      " 19  is_open                396098 non-null  int64         \n",
      " 20  categories             396098 non-null  object        \n",
      " 21  user_mean              396098 non-null  float64       \n",
      " 22  user_std               396098 non-null  float64       \n",
      " 23  user_rating_zscore     396098 non-null  float64       \n",
      " 24  sentiment_label        396098 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(7), int64(6), object(11)\n",
      "memory usage: 75.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b6966bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê°ì„± ì ìˆ˜ í¬í•¨ëœ íŒŒì¼ ì €ì¥ ì™„ë£Œ: data/merged_0503.csv\n"
     ]
    }
   ],
   "source": [
    "df_clean.to_csv(\"data/merged_0503.csv\", index=False)\n",
    "print(\"âœ… ê°ì„± ì ìˆ˜ í¬í•¨ëœ íŒŒì¼ ì €ì¥ ì™„ë£Œ: data/merged_0503.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22a726fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "ğŸ§  Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 396098/396098 [00:58<00:00, 6733.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: data/merged_0503_tokenized.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(\"data/merged_0503.csv\")\n",
    "\n",
    "# 2. DeBERTa í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "# 3. ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "input_ids_list = []\n",
    "attention_mask_list = []\n",
    "\n",
    "# 4. í…ìŠ¤íŠ¸ ì¸ì½”ë”© (max_length=128)\n",
    "for text in tqdm(df[\"cleaned_text\"], desc=\"ğŸ§  Tokenizing\"):\n",
    "    encoded = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    input_ids_list.append(encoded[\"input_ids\"])\n",
    "    attention_mask_list.append(encoded[\"attention_mask\"])\n",
    "\n",
    "# 5. ê²°ê³¼ DataFrameì— ì¶”ê°€\n",
    "df[\"input_ids\"] = input_ids_list\n",
    "df[\"attention_mask\"] = attention_mask_list\n",
    "\n",
    "# 6. JSONL íŒŒì¼ë¡œ ì €ì¥ (ë¼ì¸ë³„ ê°ì²´ êµ¬ì¡°)\n",
    "df.to_json(\"data/merged_0503_tokenized.json\", orient=\"records\", lines=True)\n",
    "\n",
    "print(\"âœ… ì €ì¥ ì™„ë£Œ: data/merged_0503_tokenized.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d208690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 396098 entries, 0 to 396097\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   review_id              396098 non-null  object        \n",
      " 1   user_id                396098 non-null  object        \n",
      " 2   business_id            396098 non-null  object        \n",
      " 3   user_rating            396098 non-null  int64         \n",
      " 4   review_useful          396098 non-null  int64         \n",
      " 5   date                   396098 non-null  datetime64[ns]\n",
      " 6   sentiment              396098 non-null  object        \n",
      " 7   cleaned_text           396098 non-null  object        \n",
      " 8   token_length           396098 non-null  int64         \n",
      " 9   user_name              396098 non-null  object        \n",
      " 10  user_review_count      396098 non-null  int64         \n",
      " 11  user_total_useful      396098 non-null  int64         \n",
      " 12  average_stars          396098 non-null  float64       \n",
      " 13  business_name          396098 non-null  object        \n",
      " 14  address                396098 non-null  object        \n",
      " 15  city                   396098 non-null  object        \n",
      " 16  state                  396098 non-null  object        \n",
      " 17  business_avg_rating    396098 non-null  float64       \n",
      " 18  business_review_count  396098 non-null  int64         \n",
      " 19  is_open                396098 non-null  int64         \n",
      " 20  categories             396098 non-null  object        \n",
      " 21  user_mean              396098 non-null  float64       \n",
      " 22  user_std               396098 non-null  float64       \n",
      " 23  user_rating_zscore     396098 non-null  float64       \n",
      " 24  sentiment_label        396098 non-null  int64         \n",
      " 25  input_ids              396098 non-null  object        \n",
      " 26  attention_mask         396098 non-null  object        \n",
      " 27  user_index             396098 non-null  int16         \n",
      " 28  biz_index              396098 non-null  int16         \n",
      "dtypes: datetime64[ns](1), float64(5), int16(2), int64(8), object(13)\n",
      "memory usage: 83.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac28022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ: data/sentiment_data.json\n",
      "âœ… ì €ì¥ ì™„ë£Œ: data/recommend_data.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. í† í°í™”ëœ ì „ì²´ ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_json(\"data/merged_0503_tokenized.json\", lines=True)\n",
    "\n",
    "# 2. ê°ì„± ë¶„ì„ìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "sentiment_cols = [\n",
    "    \"review_id\", \"user_id\", \"business_id\",\n",
    "    \"cleaned_text\", \"user_rating\", \"sentiment_label\",\n",
    "    \"input_ids\", \"attention_mask\"\n",
    "]\n",
    "df_sentiment = df[sentiment_cols]\n",
    "df_sentiment.to_json(\"data/sentiment_data.json\", orient=\"records\", lines=True)\n",
    "print(\"âœ… ì €ì¥ ì™„ë£Œ: data/sentiment_data.json\")\n",
    "\n",
    "# 3. ì¶”ì²œ ì‹œìŠ¤í…œìš© ë°ì´í„°ì…‹ ìƒì„±\n",
    "recommend_cols = [\n",
    "    \"user_id\", \"business_id\", \"user_rating\", \"sentiment_label\"\n",
    "]\n",
    "df_recommend = df[recommend_cols]\n",
    "df_recommend.to_json(\"data/recommend_data.json\", orient=\"records\", lines=True)\n",
    "print(\"âœ… ì €ì¥ ì™„ë£Œ: data/recommend_data.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
