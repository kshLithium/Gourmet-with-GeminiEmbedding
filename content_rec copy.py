#!/usr/bin/env python
# coding: utf-8

# #### import

# In[17]:


import json
import numpy as np
from collections import defaultdict
from sklearn.preprocessing import normalize
from sklearn.metrics import precision_score
from tqdm import tqdm


# ### JSONL íŒŒì¼ì—ì„œ ë¦¬ë·° ë¡œë“œ

# In[18]:


TRAIN_FILE = "dataset/train_80_random.json"
TEST_FILE = "dataset/test_20_random.json"
TOP_N = 5


def load_reviews(path):
    data = []
    with open(path, encoding="utf-8") as f:
        for line in f:
            obj = json.loads(line)
            obj["vector"] = np.array(obj["sentiment_vector"])
            data.append(obj)
    return data


train_reviews = load_reviews(TRAIN_FILE)
test_reviews = load_reviews(TEST_FILE)


# #### í›ˆë ¨ ë°ì´í„° â†’ ë²¡í„° í‰ê·  ê³„ì‚°

# In[21]:


import json, numpy as np, pandas as pd
from collections import defaultdict
from datetime import datetime
from sklearn.preprocessing import normalize

# -------------------------------------------------
# í•˜ì´í¼ íŒŒë¼ë¯¸í„°
# -------------------------------------------------
ASPECTS = ["food", "service", "price", "ambience", "location"]
HALF_LIFE = 180  # ìµœê·¼ì„± half-life (ì¼)
NEUT_THR = 0.80  # Neutral > 0.8 â‡’ ë¯¸ì–¸ê¸‰ìœ¼ë¡œ ê°„ì£¼
TOP_N = 5  # ì¶”ì²œ ê°œìˆ˜


# -------------------------------------------------
# 1. 15-D í™•ë¥  â†’ 5-D polarity
# -------------------------------------------------
# 1. 15-D í™•ë¥  â†’ 5-D polarity  (Pos,Neu,Neg ìˆœì„œìš© ë²„ì „)
def vec15_to_vec5(vec15):
    """
    vec15 = [pos, neu, neg] Ã— 5   â† â¶ ìš°ë¦¬ ë°ì´í„°ëŠ” ì´ë ‡ê²Œ ì €ì¥ë¨
    ë°˜í™˜: 5-D polarity (pos-neg)  , Neutral > 0.8 â†’ 0
    """
    out = []
    for i in range(5):
        pos, neu, neg = vec15[i * 3 : (i + 1) * 3]  # â† ì•ë’¤ë§Œ ë°”ê¿” ì¤Œ
        if neu > NEUT_THR:  # ì–¸ê¸‰ ì•ˆ ëœ aspect
            out.append(0.0)
        else:
            out.append(pos - neg)  # (-1, 1)
    return np.asarray(out, dtype=float)


# -------------------------------------------------
# 2. Âµ âˆ¥ ÏƒÂ² í’€ë§ (ìµœê·¼ì„± ê°€ì¤‘)
# -------------------------------------------------
def recency_w(days):
    return np.exp(-np.log(2) * days / HALF_LIFE)


def agg_mu_sigma(rows):
    if not rows:  # ì•ˆì „ì¥ì¹˜
        return np.zeros(10)
    now = datetime.now()
    V, W = [], []
    for v, ts in rows:
        V.append(v)
        W.append(recency_w((now - ts).days))
    V = np.vstack(V)  # (n,5)
    W = np.array(W)[:, None]  # (n,1)
    mu = (W * V).sum(0) / W.sum()
    var = (W * (V - mu) ** 2).sum(0) / W.sum()
    return np.concatenate([mu, var])  # 10-D


# -------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ
# -------------------------------------------------
def load_reviews(path):
    records = []
    with open(path, encoding="utf-8") as f:
        for line in f:
            obj = json.loads(line)
            obj["date"] = datetime.now()  # â˜… ë‚ ì§œ ì»¬ëŸ¼ ì—†ì„ ë•Œ ì„ì‹œ
            records.append(obj)
    return records


train_reviews = load_reviews("dataset/train_80_random.json")

# -------------------------------------------------
# 4. ì„ë² ë”© ìƒì„±
# -------------------------------------------------
user_rows, biz_rows = defaultdict(list), defaultdict(list)
for r in train_reviews:
    vec15 = np.array(r["sentiment_vector"], float)
    vec5 = vec15_to_vec5(vec15)
    ts = r["date"]  # ì‹¤ì œ ë‚ ì§œ ì“°ë©´ ë” ì •í™•
    user_rows[r["user_id"]].append((vec5, ts))
    biz_rows[r["business_id"]].append((vec5, ts))

user_embed = {u: agg_mu_sigma(rows) for u, rows in user_rows.items()}
biz_embed = {b: agg_mu_sigma(rows) for b, rows in biz_rows.items()}

# -------------------------------------------------
# 5. ì •ê·œí™” í›„ ìœ ì‚¬ë„ í–‰ë ¬
# -------------------------------------------------
user_ids = list(user_embed)
biz_ids = list(biz_embed)

U = normalize(np.stack([user_embed[u] for u in user_ids]))
B = normalize(np.stack([biz_embed[b] for b in biz_ids]))
scores = U @ B.T

# -------------------------------------------------
# 6. ì¶”ì²œ ìƒì„± (ì¬ë°©ë¬¸ í—ˆìš©)
# -------------------------------------------------
recommendations = {}
for i, uid in enumerate(user_ids):
    ranked_idx = np.argsort(scores[i])[::-1]
    recommendations[uid] = [biz_ids[j] for j in ranked_idx[:TOP_N]]

# ì´í›„ ground-truthÂ·í‰ê°€ ë£¨í”„ëŠ” ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©


# #### ì •ê·œí™” í›„ ìœ ì‚¬ë„ ê³„ì‚°

# In[20]:


user_ids = list(user_embed.keys())
biz_ids = list(biz_embed.keys())

user_matrix = normalize(np.stack([user_embed[u] for u in user_ids]))
biz_matrix = normalize(np.stack([biz_embed[b] for b in biz_ids]))

scores = np.dot(user_matrix, biz_matrix.T)


# #### ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ìƒì„±

# In[8]:


user2seen = defaultdict(set)
for r in train_reviews:
    user2seen[r["user_id"]].add(r["business_id"])

recommendations = {}

for i, uid in enumerate(user_ids):
    user_score = scores[i]
    ranked_idx = np.argsort(user_score)[::-1]

    recs = []
    for j in ranked_idx:
        bid = biz_ids[j]
        # if bid not in user2seen[uid]:  # ì´ë¯¸ ë³¸ ì‹ë‹¹ì€ ì œì™¸
        recs.append(bid)
        if len(recs) == TOP_N:
            break
    recommendations[uid] = recs


# #### í‰ê°€: Ground Truth ìƒì„±

# In[22]:


ground_truth = defaultdict(set)
for r in test_reviews:
    ground_truth[r["user_id"]].add(r["business_id"])


# #### Precision@K ê³„ì‚°

# In[23]:


common_users = set(recommendations.keys()) & set(ground_truth.keys())
precision_list = []

for uid in common_users:
    pred = set(recommendations[uid])
    actual = ground_truth[uid]
    hit = len(pred & actual)
    precision = hit / TOP_N
    precision_list.append(precision)


# #### ê²°ê³¼ ì¶œë ¥

# In[24]:


print(f"ğŸ“Œ í‰ê°€ ëŒ€ìƒ ìœ ì € ìˆ˜: {len(common_users)}")
print(f"ğŸ¯ Precision@{TOP_N}: {np.mean(precision_list):.4f}")


# In[ ]:


# In[ ]:


#

# In[12]:


print("train biz ìˆ˜:", len(biz_embed))
hits_in_gt = 0
total_labels = 0
for u, items in ground_truth.items():
    total_labels += len(items)
    hits_in_gt += len([b for b in items if b in biz_embed])
print("GT ë¼ë²¨ ìˆ˜:", total_labels, "ê·¸ì¤‘ train ë²¡í„° ìˆëŠ” ë¼ë²¨:", hits_in_gt)


# In[13]:


uid0 = next(iter(recommendations))
print("ìƒ˜í”Œ ìœ ì €:", uid0)
print("ì¶”ì²œ Top-10:", recommendations[uid0][:10])
print("GT ë¼ë²¨:", ground_truth.get(uid0, set()))


# In[14]:


rng = np.random.default_rng(0)
rand_hit = 0
for uid in ground_truth:
    rand_preds = rng.choice(list(biz_embed.keys()), size=5, replace=False)
    if set(rand_preds) & ground_truth[uid]:
        rand_hit += 1
print("ë¬´ì‘ìœ„ P@5 â‰ˆ", rand_hit / len(ground_truth))


# In[15]:


print("TOP_N =", TOP_N)


# In[ ]:


# In[16]:


import numpy as np, json, random, math

path = "dataset/train_80_random.json"
sample = json.loads(open(path).readline())

triplet = np.array(sample["sentiment_vector"][:3])  # food
print("food triplet:", triplet.round(3))

if triplet.argmax() == 0:
    print("ìˆœì„œ Pos,Neu,Neg  (ë’¤ì§‘í˜)")
elif triplet.argmax() == 2:
    print("ìˆœì„œ Neg,Neu,Pos  (ì •ìƒ)")
else:
    print("Neutralì´ ìµœëŒ€ â†’ ì–¸ê¸‰ ì•ˆ ëê±°ë‚˜ ë¬´ê°ì •")


# In[ ]:
