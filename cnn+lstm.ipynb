{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7586f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… MPS ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# âœ… CNN+LSTM ëª¨ë¸ ì •ì˜\n",
    "class CNNLSTMSentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=30522, embedding_dim=64, hidden_dim=32, num_classes=3, dropout=0.5, padding_idx=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.conv = nn.Conv1d(embedding_dim, 64, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids)       # (B, L, E)\n",
    "        x = x.permute(0, 2, 1)              # (B, E, L)\n",
    "        x = self.relu(self.conv(x))        # (B, C, L)\n",
    "        x = x.permute(0, 2, 1)              # (B, L, C)\n",
    "        lstm_out, _ = self.lstm(x)          # (B, L, H*2)\n",
    "        pooled = torch.mean(lstm_out, dim=1)\n",
    "        return self.fc(self.dropout(pooled))\n",
    "\n",
    "# âœ… Dataset ì •ì˜\n",
    "class DeBERTaSentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_length=128):\n",
    "        self.df = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        input_ids = torch.tensor(row[\"input_ids\"][:self.max_length], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(row[\"attention_mask\"][:self.max_length], dtype=torch.long)\n",
    "        label = torch.tensor(row[\"sentiment_label\"], dtype=torch.long)\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë“œ ë° ë¶„í• \n",
    "df = pd.read_json(\"data/merged_0503_tokenized.json\", lines=True)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# âœ… DataLoader êµ¬ì„±\n",
    "train_dataset = DeBERTaSentimentDataset(train_df)\n",
    "val_dataset = DeBERTaSentimentDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# âœ… ëª¨ë¸, ì˜µí‹°ë§ˆì´ì €, ì†ì‹¤í•¨ìˆ˜\n",
    "model = CNNLSTMSentimentClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# âœ… í•™ìŠµ í•¨ìˆ˜ (ETA í¬í•¨)\n",
    "def train_model(model, dataloader, optimizer, criterion, device, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        total = len(dataloader)\n",
    "        pbar = tqdm(enumerate(dataloader), total=total, desc=f\"ğŸ“˜ Epoch {epoch}/{epochs}\")\n",
    "        for step, batch in pbar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            eta = (elapsed / (step + 1)) * (total - step - 1)\n",
    "            pbar.set_postfix({\n",
    "                \"Loss\": f\"{loss.item():.4f}\",\n",
    "                \"Elapsed\": f\"{elapsed:.1f}s\",\n",
    "                \"ETA\": f\"{eta:.1f}s\"\n",
    "            })\n",
    "\n",
    "        avg_loss = total_loss / total\n",
    "        print(f\"âœ… Epoch {epoch} ì™„ë£Œ | í‰ê·  Loss: {avg_loss:.4f} | ì´ ì†Œìš”: {time.time() - start_time:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1ff831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9903/9903 [06:19<00:00, 26.10it/s, Loss=0.9981, Elapsed=379.4s, ETA=0.0s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1 ì™„ë£Œ | í‰ê·  Loss: 1.0055 | ì´ ì†Œìš”: 379.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9903/9903 [06:28<00:00, 25.47it/s, Loss=0.8069, Elapsed=388.8s, ETA=0.0s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2 ì™„ë£Œ | í‰ê·  Loss: 0.9342 | ì´ ì†Œìš”: 388.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9903/9903 [06:10<00:00, 26.70it/s, Loss=0.8779, Elapsed=370.9s, ETA=0.0s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3 ì™„ë£Œ | í‰ê·  Loss: 0.8996 | ì´ ì†Œìš”: 370.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… í•™ìŠµ ì‹œì‘\n",
    "train_model(model, train_loader, optimizer, criterion, device, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf6298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# âœ… ê²€ì¦ í•¨ìˆ˜ (Validation or Test)\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"ğŸ” Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"negative\", \"neutral\", \"positive\"])\n",
    "    print(f\"\\nâœ… ì •í™•ë„: {acc:.4f}\\n\")\n",
    "    print(\"ğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\\n\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d146961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1238/1238 [00:17<00:00, 72.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì •í™•ë„: 0.5625\n",
      "\n",
      "ğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.66      0.65     11231\n",
      "     neutral       0.46      0.36      0.40     13972\n",
      "    positive       0.58      0.68      0.63     14407\n",
      "\n",
      "    accuracy                           0.56     39610\n",
      "   macro avg       0.56      0.57      0.56     39610\n",
      "weighted avg       0.55      0.56      0.55     39610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ í›„ ê²€ì¦ ì„¸íŠ¸ë¡œ ì„±ëŠ¥ í‰ê°€\n",
    "# evaluate_model(model, val_loader, device)\n",
    "\n",
    "# ë˜ëŠ” ìµœì¢… í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n",
    "test_dataset = DeBERTaSentimentDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc93876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
