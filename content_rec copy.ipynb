{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fba0704",
   "metadata": {},
   "source": [
    "#### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import precision_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb090a0f",
   "metadata": {},
   "source": [
    "### JSONL íŒŒì¼ì—ì„œ ë¦¬ë·° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f39936",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"dataset/train_80_random.json\"\n",
    "TEST_FILE = \"dataset/test_20_random.json\"\n",
    "TOP_N = 5\n",
    "\n",
    "\n",
    "def load_reviews(path):\n",
    "    data = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            obj[\"vector\"] = np.array(obj[\"sentiment_vector\"])\n",
    "            data.append(obj)\n",
    "    return data\n",
    "\n",
    "\n",
    "train_reviews = load_reviews(TRAIN_FILE)\n",
    "test_reviews = load_reviews(TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57c31c",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨ ë°ì´í„° â†’ ë²¡í„° í‰ê·  ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf508ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# -------------------------------------------------\n",
    "# í•˜ì´í¼ íŒŒë¼ë¯¸í„°\n",
    "# -------------------------------------------------\n",
    "ASPECTS = [\"food\", \"service\", \"price\", \"ambience\", \"location\"]\n",
    "HALF_LIFE = 180  # ìµœê·¼ì„± half-life (ì¼)\n",
    "NEUT_THR = 0.80  # Neutral > 0.8 â‡’ ë¯¸ì–¸ê¸‰ìœ¼ë¡œ ê°„ì£¼\n",
    "TOP_N = 5  # ì¶”ì²œ ê°œìˆ˜\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. 15-D í™•ë¥  â†’ 5-D polarity\n",
    "# -------------------------------------------------\n",
    "# 1. 15-D í™•ë¥  â†’ 5-D polarity  (Pos,Neu,Neg ìˆœì„œìš© ë²„ì „)\n",
    "def vec15_to_vec5(vec15):\n",
    "    \"\"\"\n",
    "    vec15 = [pos, neu, neg] Ã— 5   â† â¶ ìš°ë¦¬ ë°ì´í„°ëŠ” ì´ë ‡ê²Œ ì €ì¥ë¨\n",
    "    ë°˜í™˜: 5-D polarity (pos-neg)  , Neutral > 0.8 â†’ 0\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(5):\n",
    "        pos, neu, neg = vec15[i * 3 : (i + 1) * 3]  # â† ì•ë’¤ë§Œ ë°”ê¿” ì¤Œ\n",
    "        if neu > NEUT_THR:  # ì–¸ê¸‰ ì•ˆ ëœ aspect\n",
    "            out.append(0.0)\n",
    "        else:\n",
    "            out.append(pos - neg)  # (-1, 1)\n",
    "    return np.asarray(out, dtype=float)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Âµ âˆ¥ ÏƒÂ² í’€ë§ (ìµœê·¼ì„± ê°€ì¤‘)\n",
    "# -------------------------------------------------\n",
    "def recency_w(days):\n",
    "    return np.exp(-np.log(2) * days / HALF_LIFE)\n",
    "\n",
    "\n",
    "def agg_mu_sigma(rows):\n",
    "    if not rows:  # ì•ˆì „ì¥ì¹˜\n",
    "        return np.zeros(10)\n",
    "    now = datetime.now()\n",
    "    V, W = [], []\n",
    "    for v, ts in rows:\n",
    "        V.append(v)\n",
    "        W.append(recency_w((now - ts).days))\n",
    "    V = np.vstack(V)  # (n,5)\n",
    "    W = np.array(W)[:, None]  # (n,1)\n",
    "    mu = (W * V).sum(0) / W.sum()\n",
    "    var = (W * (V - mu) ** 2).sum(0) / W.sum()\n",
    "    return np.concatenate([mu, var])  # 10-D\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. ë°ì´í„° ë¡œë“œ\n",
    "# -------------------------------------------------\n",
    "def load_reviews(path):\n",
    "    records = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            obj[\"date\"] = datetime.now()  # â˜… ë‚ ì§œ ì»¬ëŸ¼ ì—†ì„ ë•Œ ì„ì‹œ\n",
    "            records.append(obj)\n",
    "    return records\n",
    "\n",
    "\n",
    "train_reviews = load_reviews(\"dataset/train_80_random.json\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. ì„ë² ë”© ìƒì„±\n",
    "# -------------------------------------------------\n",
    "user_rows, biz_rows = defaultdict(list), defaultdict(list)\n",
    "for r in train_reviews:\n",
    "    vec15 = np.array(r[\"sentiment_vector\"], float)\n",
    "    vec5 = vec15_to_vec5(vec15)\n",
    "    ts = r[\"date\"]  # ì‹¤ì œ ë‚ ì§œ ì“°ë©´ ë” ì •í™•\n",
    "    user_rows[r[\"user_id\"]].append((vec5, ts))\n",
    "    biz_rows[r[\"business_id\"]].append((vec5, ts))\n",
    "\n",
    "user_embed = {u: agg_mu_sigma(rows) for u, rows in user_rows.items()}\n",
    "biz_embed = {b: agg_mu_sigma(rows) for b, rows in biz_rows.items()}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. ì •ê·œí™” í›„ ìœ ì‚¬ë„ í–‰ë ¬\n",
    "# -------------------------------------------------\n",
    "user_ids = list(user_embed)\n",
    "biz_ids = list(biz_embed)\n",
    "\n",
    "U = normalize(np.stack([user_embed[u] for u in user_ids]))\n",
    "B = normalize(np.stack([biz_embed[b] for b in biz_ids]))\n",
    "scores = U @ B.T\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. ì¶”ì²œ ìƒì„± (ì¬ë°©ë¬¸ í—ˆìš©)\n",
    "# -------------------------------------------------\n",
    "recommendations = {}\n",
    "for i, uid in enumerate(user_ids):\n",
    "    ranked_idx = np.argsort(scores[i])[::-1]\n",
    "    recommendations[uid] = [biz_ids[j] for j in ranked_idx[:TOP_N]]\n",
    "\n",
    "# ì´í›„ ground-truthÂ·í‰ê°€ ë£¨í”„ëŠ” ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe4eba",
   "metadata": {},
   "source": [
    "#### ì •ê·œí™” í›„ ìœ ì‚¬ë„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2b76fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = list(user_embed.keys())\n",
    "biz_ids = list(biz_embed.keys())\n",
    "\n",
    "user_matrix = normalize(np.stack([user_embed[u] for u in user_ids]))\n",
    "biz_matrix = normalize(np.stack([biz_embed[b] for b in biz_ids]))\n",
    "\n",
    "scores = np.dot(user_matrix, biz_matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5a4af",
   "metadata": {},
   "source": [
    "#### ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43876ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2seen = defaultdict(set)\n",
    "for r in train_reviews:\n",
    "    user2seen[r[\"user_id\"]].add(r[\"business_id\"])\n",
    "\n",
    "recommendations = {}\n",
    "\n",
    "for i, uid in enumerate(user_ids):\n",
    "    user_score = scores[i]\n",
    "    ranked_idx = np.argsort(user_score)[::-1]\n",
    "\n",
    "    recs = []\n",
    "    for j in ranked_idx:\n",
    "        bid = biz_ids[j]\n",
    "        # if bid not in user2seen[uid]:  # ì´ë¯¸ ë³¸ ì‹ë‹¹ì€ ì œì™¸\n",
    "        recs.append(bid)\n",
    "        if len(recs) == TOP_N:\n",
    "            break\n",
    "    recommendations[uid] = recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac660779",
   "metadata": {},
   "source": [
    "#### í‰ê°€: Ground Truth ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb182ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = defaultdict(set)\n",
    "for r in test_reviews:\n",
    "    ground_truth[r[\"user_id\"]].add(r[\"business_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbabd76",
   "metadata": {},
   "source": [
    "#### Precision@K ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462d6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users = set(recommendations.keys()) & set(ground_truth.keys())\n",
    "precision_list = []\n",
    "\n",
    "for uid in common_users:\n",
    "    pred = set(recommendations[uid])\n",
    "    actual = ground_truth[uid]\n",
    "    hit = len(pred & actual)\n",
    "    precision = hit / TOP_N\n",
    "    precision_list.append(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2c7c0e",
   "metadata": {},
   "source": [
    "#### ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77ce7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ í‰ê°€ ëŒ€ìƒ ìœ ì € ìˆ˜: 24004\n",
      "ğŸ¯ Precision@5: 0.0009\n"
     ]
    }
   ],
   "source": [
    "print(f\"ğŸ“Œ í‰ê°€ ëŒ€ìƒ ìœ ì € ìˆ˜: {len(common_users)}\")\n",
    "print(f\"ğŸ¯ Precision@{TOP_N}: {np.mean(precision_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44237db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4e1eb76",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26d24e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train biz ìˆ˜: 6865\n",
      "GT ë¼ë²¨ ìˆ˜: 89593 ê·¸ì¤‘ train ë²¡í„° ìˆëŠ” ë¼ë²¨: 89556\n"
     ]
    }
   ],
   "source": [
    "print(\"train biz ìˆ˜:\", len(biz_embed))\n",
    "hits_in_gt = 0\n",
    "total_labels = 0\n",
    "for u, items in ground_truth.items():\n",
    "    total_labels += len(items)\n",
    "    hits_in_gt += len([b for b in items if b in biz_embed])\n",
    "print(\"GT ë¼ë²¨ ìˆ˜:\", total_labels, \"ê·¸ì¤‘ train ë²¡í„° ìˆëŠ” ë¼ë²¨:\", hits_in_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9645aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒ˜í”Œ ìœ ì €: RHfA_QRRITTjpatBHOmH0w\n",
      "ì¶”ì²œ Top-10: ['BaSwNEingTmrBw4shffK5w', '4PyqPHAiFopyZZlLcLQuVg', 'oqbhVgliVJH-iRa3AnD-3A', 'ekxvAyD2T5v3GS7n4X_3dQ', 'UyTx6ci7ATsWco_mE4J8Jw']\n",
      "GT ë¼ë²¨: {'el-WV1mOpFmrQOowLnh4aw', 'NFzfuIFghE-HnrodHpaT6A'}\n"
     ]
    }
   ],
   "source": [
    "uid0 = next(iter(recommendations))\n",
    "print(\"ìƒ˜í”Œ ìœ ì €:\", uid0)\n",
    "print(\"ì¶”ì²œ Top-10:\", recommendations[uid0][:10])\n",
    "print(\"GT ë¼ë²¨:\", ground_truth.get(uid0, set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "586ccde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬´ì‘ìœ„ P@5 â‰ˆ 0.002791201466422263\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "rand_hit = 0\n",
    "for uid in ground_truth:\n",
    "    rand_preds = rng.choice(list(biz_embed.keys()), size=5, replace=False)\n",
    "    if set(rand_preds) & ground_truth[uid]:\n",
    "        rand_hit += 1\n",
    "print(\"ë¬´ì‘ìœ„ P@5 â‰ˆ\", rand_hit / len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02a5d14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP_N = 5\n"
     ]
    }
   ],
   "source": [
    "print(\"TOP_N =\", TOP_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4fa6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4c6099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food triplet: [0.983 0.012 0.005]\n",
      "ìˆœì„œ Pos,Neu,Neg  (ë’¤ì§‘í˜)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, json, random, math\n",
    "\n",
    "path = \"dataset/train_80_random.json\"\n",
    "sample = json.loads(open(path).readline())\n",
    "\n",
    "triplet = np.array(sample[\"sentiment_vector\"][:3])  # food\n",
    "print(\"food triplet:\", triplet.round(3))\n",
    "\n",
    "if triplet.argmax() == 0:\n",
    "    print(\"ìˆœì„œ Pos,Neu,Neg  (ë’¤ì§‘í˜)\")\n",
    "elif triplet.argmax() == 2:\n",
    "    print(\"ìˆœì„œ Neg,Neu,Pos  (ì •ìƒ)\")\n",
    "else:\n",
    "    print(\"Neutralì´ ìµœëŒ€ â†’ ì–¸ê¸‰ ì•ˆ ëê±°ë‚˜ ë¬´ê°ì •\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a9fb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_embed shape: (10,)\n",
      "ì½”ì‚¬ì¸ ë¶„ì‚°: 0.4244610929238665\n",
      "ì¶”ì²œ ì˜ˆì‹œ: ['BaSwNEingTmrBw4shffK5w', '4PyqPHAiFopyZZlLcLQuVg', 'oqbhVgliVJH-iRa3AnD-3A', 'ekxvAyD2T5v3GS7n4X_3dQ', 'UyTx6ci7ATsWco_mE4J8Jw']\n"
     ]
    }
   ],
   "source": [
    "print(\"user_embed shape:\", next(iter(user_embed.values())).shape)\n",
    "print(\"ì½”ì‚¬ì¸ ë¶„ì‚°:\", np.std((U @ B.T).ravel()))\n",
    "print(\"ì¶”ì²œ ì˜ˆì‹œ:\", recommendations[user_ids[0]][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e518ccfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ 5ê°œ: ['BaSwNEingTmrBw4shffK5w', '4PyqPHAiFopyZZlLcLQuVg', 'oqbhVgliVJH-iRa3AnD-3A', 'ekxvAyD2T5v3GS7n4X_3dQ', 'UyTx6ci7ATsWco_mE4J8Jw']\n",
      "GT ë¼ë²¨: {'NFzfuIFghE-HnrodHpaT6A', 'el-WV1mOpFmrQOowLnh4aw'}\n",
      "êµì§‘í•©: set()\n"
     ]
    }
   ],
   "source": [
    "uid0 = user_ids[0]\n",
    "print(\"ì¶”ì²œ 5ê°œ:\", recommendations[uid0])\n",
    "print(\"GT ë¼ë²¨:\", ground_truth.get(uid0, set()))\n",
    "print(\"êµì§‘í•©:\", set(recommendations[uid0]) & ground_truth.get(uid0, set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261e357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ ì‚¬ë„ ìŒìˆ˜ ë¹„ìœ¨: 0.09744979046724148\n"
     ]
    }
   ],
   "source": [
    "neg_cnt = sum((U @ B.T).ravel() < 0)\n",
    "print(\"ìœ ì‚¬ë„ ìŒìˆ˜ ë¹„ìœ¨:\", neg_cnt / (U.shape[0] * B.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c95b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = np.maximum(0, U @ B.T)  # ìŒìˆ˜ 0 í´ë¨í•‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94016ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
