{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2b0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d51c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# âœ… 1. íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_json(\"data/merged_0503_tokenized.json\", lines=True)\n",
    "\n",
    "# âœ… 2. íƒ€ì… í™•ì¸ (ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸í•˜ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "assert isinstance(df[\"input_ids\"].iloc[0], list), \"input_idsê°€ ë¦¬ìŠ¤íŠ¸ íƒ€ì…ì´ ì•„ë‹˜\"\n",
    "\n",
    "# âœ… 3. Dataset ì •ì˜\n",
    "class DeBERTaSentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_length=128):\n",
    "        self.df = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        input_ids = torch.tensor(row[\"input_ids\"][:self.max_length], dtype=torch.long)\n",
    "        attention_mask = torch.tensor(row[\"attention_mask\"][:self.max_length], dtype=torch.long)\n",
    "        label = torch.tensor(row[\"sentiment_label\"], dtype=torch.long)\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "# âœ… 4. DataLoader êµ¬ì„±\n",
    "dataset = DeBERTaSentimentDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb08738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: mps\n"
     ]
    }
   ],
   "source": [
    "# âœ… ë””ë°”ì´ìŠ¤ ì„¤ì • (GPUëŠ” ë¬´ì‹œí•˜ê³  MPS or CPUë§Œ ì‚¬ìš©)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# âœ… CNN ëª¨ë¸ ì •ì˜\n",
    "class CNNSentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=30522, embedding_dim=300, num_classes=3, dropout=0.5, padding_idx=1):\n",
    "        super(CNNSentimentClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=300, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(output_size=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(300, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids)        # (B, L, E)\n",
    "        x = x.permute(0, 2, 1)               # (B, E, L)\n",
    "        x = F.relu(self.conv(x))            # (B, C, L)\n",
    "        x = self.pool(x).squeeze(-1)        # (B, C)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)                   # (B, num_classes)\n",
    "\n",
    "# âœ… í•™ìŠµ í•¨ìˆ˜\n",
    "def train_model(model, dataloader, optimizer, criterion, device, epochs=1):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nğŸ“˜ Epoch {epoch+1}/{epochs}\")\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\")\n",
    "        for step, batch in pbar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            avg_loss = total_loss / (step + 1)\n",
    "            elapsed = time.time() - start_time\n",
    "            eta = (elapsed / (step + 1)) * (len(dataloader) - step - 1)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"Loss\": f\"{avg_loss:.4f}\",\n",
    "                \"Elapsed\": f\"{elapsed:.1f}s\",\n",
    "                \"ETA\": f\"{eta:.1f}s\"\n",
    "            })\n",
    "\n",
    "        print(f\"âœ… Epoch {epoch+1} ì™„ë£Œ | í‰ê·  Loss: {avg_loss:.4f} | ì´ ì†Œìš”: {elapsed:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ad4e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“˜ Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:22<00:00, 38.36it/s, Loss=0.9620, Elapsed=322.7s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1 ì™„ë£Œ | í‰ê·  Loss: 0.9620 | ì´ ì†Œìš”: 322.7s\n",
      "\n",
      "ğŸ“˜ Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:25<00:00, 37.97it/s, Loss=0.8931, Elapsed=326.0s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2 ì™„ë£Œ | í‰ê·  Loss: 0.8931 | ì´ ì†Œìš”: 326.0s\n",
      "\n",
      "ğŸ“˜ Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:28<00:00, 37.71it/s, Loss=0.8747, Elapsed=328.3s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3 ì™„ë£Œ | í‰ê·  Loss: 0.8747 | ì´ ì†Œìš”: 328.3s\n",
      "\n",
      "ğŸ“˜ Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:43<00:00, 36.08it/s, Loss=0.8621, Elapsed=343.1s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 4 ì™„ë£Œ | í‰ê·  Loss: 0.8621 | ì´ ì†Œìš”: 343.1s\n",
      "\n",
      "ğŸ“˜ Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:44<00:00, 35.96it/s, Loss=0.8509, Elapsed=344.3s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 5 ì™„ë£Œ | í‰ê·  Loss: 0.8509 | ì´ ì†Œìš”: 344.3s\n",
      "\n",
      "ğŸ“˜ Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:39<00:00, 36.45it/s, Loss=0.8407, Elapsed=339.7s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 6 ì™„ë£Œ | í‰ê·  Loss: 0.8407 | ì´ ì†Œìš”: 339.7s\n",
      "\n",
      "ğŸ“˜ Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:27<00:00, 37.85it/s, Loss=0.8316, Elapsed=327.1s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 7 ì™„ë£Œ | í‰ê·  Loss: 0.8316 | ì´ ì†Œìš”: 327.1s\n",
      "\n",
      "ğŸ“˜ Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:26<00:00, 37.97it/s, Loss=0.8228, Elapsed=326.0s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 8 ì™„ë£Œ | í‰ê·  Loss: 0.8228 | ì´ ì†Œìš”: 326.0s\n",
      "\n",
      "ğŸ“˜ Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:12<00:00, 39.55it/s, Loss=0.8141, Elapsed=313.0s, ETA=0.0s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 9 ì™„ë£Œ | í‰ê·  Loss: 0.8141 | ì´ ì†Œìš”: 313.0s\n",
      "\n",
      "ğŸ“˜ Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [05:25<00:00, 38.08it/s, Loss=0.8050, Elapsed=325.1s, ETA=0.0s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 10 ì™„ë£Œ | í‰ê·  Loss: 0.8050 | ì´ ì†Œìš”: 325.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNNSentimentClassifier()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_model(model, dataloader, optimizer, criterion, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07715a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"ğŸ“Š Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # sklearn í‰ê°€\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=[\"negative\", \"neutral\", \"positive\"], digits=4)\n",
    "\n",
    "    print(f\"\\nâœ… ì •í™•ë„: {accuracy:.4f}\")\n",
    "    print(\"\\nğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\\n\")\n",
    "    print(report)\n",
    "\n",
    "    return accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e133e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12379/12379 [01:47<00:00, 115.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì •í™•ë„: 0.6569\n",
      "\n",
      "ğŸ“‹ ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7398    0.7431    0.7414    112726\n",
      "     neutral     0.5732    0.4658    0.5139    139184\n",
      "    positive     0.6575    0.7741    0.7110    144188\n",
      "\n",
      "    accuracy                         0.6569    396098\n",
      "   macro avg     0.6568    0.6610    0.6555    396098\n",
      "weighted avg     0.6513    0.6569    0.6504    396098\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6569359098001,\n",
       " '              precision    recall  f1-score   support\\n\\n    negative     0.7398    0.7431    0.7414    112726\\n     neutral     0.5732    0.4658    0.5139    139184\\n    positive     0.6575    0.7741    0.7110    144188\\n\\n    accuracy                         0.6569    396098\\n   macro avg     0.6568    0.6610    0.6555    396098\\nweighted avg     0.6513    0.6569    0.6504    396098\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b451d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
