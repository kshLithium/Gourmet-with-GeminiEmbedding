#!/usr/bin/env python
# coding: utf-8

# #### import

# In[2]:


import json
import numpy as np
from collections import defaultdict
from sklearn.preprocessing import normalize
from sklearn.metrics import precision_score
from sklearn.decomposition import TruncatedSVD
from tqdm import tqdm
import random
import pandas as pd
from scipy.sparse import csr_matrix


# ### JSONL íŒŒì¼ì—ì„œ ë¦¬ë·° ë¡œë“œ

# In[3]:


TRAIN_FILE = "dataset/train_80.json"
TEST_FILE = "dataset/test_20.json"
TOP_N = 5
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ ìƒ˜í”Œë§ ë¹„ìœ¨ ì„¤ì •
SAMPLE_RATIO = 0.2  # 20%ì˜ ìœ ì €ë§Œ ì‚¬ìš©
USE_CF = True  # í˜‘ì—… í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
USE_CATEGORY = True  # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€


def load_reviews(path):
    data = []
    with open(path, encoding="utf-8") as f:
        for line in f:
            obj = json.loads(line)
            obj["vector"] = np.array(obj["sentiment_vector"])
            data.append(obj)
    return data


print("ë¦¬ë·° ë°ì´í„° ë¡œë“œ ì¤‘...")
train_reviews = load_reviews(TRAIN_FILE)
test_reviews = load_reviews(TEST_FILE)

# ìœ ì € ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´)
all_user_ids = list(set(r["user_id"] for r in train_reviews))
sampled_user_ids = set(
    random.sample(all_user_ids, int(len(all_user_ids) * SAMPLE_RATIO))
)

print(
    f"ì´ {len(all_user_ids)}ëª…ì˜ ìœ ì € ì¤‘ {len(sampled_user_ids)}ëª… ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ìœ„í•´)"
)

# ìƒ˜í”Œë§ëœ ìœ ì €ì˜ ë¦¬ë·°ë§Œ í•„í„°ë§ (í›ˆë ¨ ë°ì´í„°)
sampled_train_reviews = [r for r in train_reviews if r["user_id"] in sampled_user_ids]

print(f"ìƒ˜í”Œë§ í›„ í›ˆë ¨ ë¦¬ë·° ìˆ˜: {len(sampled_train_reviews)}/{len(train_reviews)}")

# ì¹´í…Œê³ ë¦¬ ì •ë³´ ëª¨ì˜ ì¶”ê°€ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ í•„ìš”í•œ ì‹ë‹¹ë§Œ)
if USE_CATEGORY:
    print("ì‹ë‹¹ ì¹´í…Œê³ ë¦¬ ì •ë³´ ìƒì„± ì¤‘...")
    business_ids = set()
    for r in sampled_train_reviews:
        business_ids.add(r["business_id"])

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œë§ëœ ìœ ì €ì˜ ì‹ë‹¹ ì¶”ê°€
    for r in test_reviews:
        if r["user_id"] in sampled_user_ids:
            business_ids.add(r["business_id"])

    # 5ê°œì˜ ì¹´í…Œê³ ë¦¬ ìƒì„±
    categories = ["ì¹´í…Œê³ ë¦¬_" + str(i) for i in range(5)]
    biz_categories = {}
    for bid in business_ids:
        # ê° ì‹ë‹¹ì€ 1~2ê°œì˜ ëœë¤ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì§
        n_cats = random.randint(1, 2)
        biz_categories[bid] = random.sample(categories, n_cats)

    print(f"{len(business_ids)}ê°œ ì‹ë‹¹ì— ì¹´í…Œê³ ë¦¬ í• ë‹¹ ì™„ë£Œ")
else:
    business_ids = set()
    for r in sampled_train_reviews:
        business_ids.add(r["business_id"])
    print("ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§ ë¹„í™œì„±í™”")


# ### 1. ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ (ê¸°ì¡´ ë°©ì‹)

# #### í›ˆë ¨ ë°ì´í„° â†’ ë²¡í„° í‰ê·  ê³„ì‚°

# In[3]:

print("\n[1] ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ ì¤€ë¹„ ì¤‘...")

# ì½˜í…ì¸  ê¸°ë°˜ ë²¡í„° í‘œí˜„
user_vecs = defaultdict(list)
biz_vecs = defaultdict(list)

for r in sampled_train_reviews:
    user_vecs[r["user_id"]].append(r["vector"])
    biz_vecs[r["business_id"]].append(r["vector"])

user_embed = {u: np.mean(vs, axis=0) for u, vs in user_vecs.items()}
biz_embed = {b: np.mean(vs, axis=0) for b, vs in biz_vecs.items()}

# ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ê³ ê¸‰ ë²¡í„° í‘œí˜„ (íŠ¹ì„± ì¤‘ìš”ë„ ì¡°ì •)
# ì¼ë°˜ì ìœ¼ë¡œ Positive ê°ì„±ì´ ì¶”ì²œì— ë” ì˜í–¥ë ¥ì´ í¼
aspect_weights = np.ones(15)  # 15ì°¨ì› ê°ì„± ë²¡í„° (5 aspects x 3 sentiments)
# Positive ê°ì„± ê°€ì¤‘ì¹˜ ë†’ì„ (ì¸ë±ìŠ¤: 2, 5, 8, 11, 14)
for i in [2, 5, 8, 11, 14]:
    aspect_weights[i] = 2.5
# Negative ê°ì„± ê°€ì¤‘ì¹˜ ì•½ê°„ ë†’ì„ (ì¸ë±ìŠ¤: 0, 3, 6, 9, 12)
for i in [0, 3, 6, 9, 12]:
    aspect_weights[i] = 1.5

# ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ë²¡í„° ê³„ì‚°
user_embed_weighted = {}
biz_embed_weighted = {}

for u, vec in user_embed.items():
    user_embed_weighted[u] = vec * aspect_weights

for b, vec in biz_embed.items():
    biz_embed_weighted[b] = vec * aspect_weights


# #### ì •ê·œí™” í›„ ìœ ì‚¬ë„ ê³„ì‚°

# In[4]:

print("ì½˜í…ì¸  ìœ ì‚¬ë„ ê³„ì‚° ì¤‘...")

user_ids = list(user_embed_weighted.keys())
biz_ids = list(biz_embed_weighted.keys())

user_matrix = normalize(np.stack([user_embed_weighted[u] for u in user_ids]))
biz_matrix = normalize(np.stack([biz_embed_weighted[b] for b in biz_ids]))

scores_content = np.dot(user_matrix, biz_matrix.T)


# ### 2. ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ (ë² ì´ìŠ¤ë¼ì¸)

# In[5]:

print("\n[2] ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ ì¤€ë¹„ ì¤‘...")

# ê° ì‹ë‹¹ë³„ ë¦¬ë·° ìˆ˜ ê³„ì‚°
biz_popularity = defaultdict(int)
for r in sampled_train_reviews:
    biz_popularity[r["business_id"]] += 1

# ì¸ê¸°ë„ ìˆœìœ¼ë¡œ ì‹ë‹¹ ì •ë ¬
popular_items = sorted(biz_popularity.items(), key=lambda x: x[1], reverse=True)
popular_biz_ids = [item[0] for item in popular_items]


# ### 3. í˜‘ì—… í•„í„°ë§ êµ¬í˜„ (ë©”ëª¨ë¦¬ íš¨ìœ¨ ê°œì„ )

# In[6]:

scores_cf = {}
if USE_CF:
    print("\n[3] í˜‘ì—… í•„í„°ë§ ì¤€ë¹„ ì¤‘...")

    # ê° ì‚¬ìš©ìê°€ ë°©ë¬¸í•œ ì‹ë‹¹ ì§‘í•© ìƒì„±
    user_items = defaultdict(set)

    for r in sampled_train_reviews:
        user_id = r["user_id"]
        biz_id = r["business_id"]
        user_items[user_id].add(biz_id)

    print(f"ìœ ì €-ì•„ì´í…œ ìƒí˜¸ì‘ìš© ìƒì„± ì™„ë£Œ: {len(user_items)}ëª…ì˜ ìœ ì €")

    # ê°„ë‹¨í•œ ì‚¬ìš©ì ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ (User-based CF)
    # ìì¹´ë“œ ìœ ì‚¬ë„ ì‚¬ìš© (ë‘ ì§‘í•©ì˜ êµì§‘í•© / í•©ì§‘í•©)
    scores_cf = defaultdict(dict)

    # ì¸ê¸°ë„ ê¸°ì¤€ ìƒìœ„ ì‹ë‹¹ë§Œ ê³ ë ¤ (ë” ì ì€ ê³„ì‚°ëŸ‰)
    top_popular_biz_ids = set(popular_biz_ids[:500])  # ìƒìœ„ 500ê°œ ì‹ë‹¹ë§Œ ì‚¬ìš©

    for user_id in tqdm(sampled_user_ids, desc="í˜‘ì—… í•„í„°ë§ ì²˜ë¦¬ ì¤‘"):
        user_visited = user_items[user_id]

        # ìœ ì‚¬ ì‚¬ìš©ì ì°¾ê¸° - ë¬´ì‘ìœ„ ìƒ˜í”Œë§ìœ¼ë¡œ ê³„ì‚°ëŸ‰ ê°ì†Œ
        sampled_users = random.sample(
            list(user_items.keys()), min(100, len(user_items))
        )
        similar_users = []

        for other_id in sampled_users:
            if other_id == user_id:
                continue

            other_visited = user_items[other_id]

            # êµì§‘í•©ê³¼ í•©ì§‘í•© í¬ê¸° ê³„ì‚°
            intersection = len(user_visited & other_visited)
            union = len(user_visited | other_visited)

            if union > 0 and intersection > 0:  # ìœ ì‚¬ë„ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                jaccard = intersection / union
                similar_users.append((other_id, jaccard))

        # ìœ ì‚¬ë„ ê¸°ì¤€ ìƒìœ„ 10ëª…ë§Œ ì„ íƒ
        similar_users.sort(key=lambda x: x[1], reverse=True)
        top_similar_users = similar_users[:10]

        # ì¶”ì²œ ì‹ë‹¹ ì ìˆ˜ ê³„ì‚°
        for biz_id in top_popular_biz_ids:
            if biz_id in user_visited:  # ì´ë¯¸ ë°©ë¬¸í•œ ê³³ì€ ì œì™¸
                continue

            score = 0
            for other_id, similarity in top_similar_users:
                if biz_id in user_items[other_id]:
                    score += similarity

            if score > 0:  # ì ìˆ˜ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì €ì¥
                scores_cf[user_id][biz_id] = score
else:
    print("í˜‘ì—… í•„í„°ë§ ë¹„í™œì„±í™”")


# ### 4. ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§

# In[7]:

scores_category = {}
if USE_CATEGORY:
    print("\n[4] ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§ ì¤€ë¹„ ì¤‘...")

    # ì‚¬ìš©ìë³„ ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ê³„ì‚°
    user_category_prefs = defaultdict(lambda: defaultdict(int))

    for r in sampled_train_reviews:
        user_id = r["user_id"]
        biz_id = r["business_id"]
        if biz_id in biz_categories:
            for category in biz_categories[biz_id]:
                user_category_prefs[user_id][category] += 1

    # ì‚¬ìš©ì ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ì •ê·œí™”
    for user_id, categories in user_category_prefs.items():
        total = sum(categories.values())
        for cat in categories:
            categories[cat] /= total

    # ì¹´í…Œê³ ë¦¬ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    scores_category = {}
    for user_id in sampled_user_ids:
        scores_category[user_id] = {}
        user_prefs = user_category_prefs.get(user_id, {})

        for biz_id in business_ids:
            if biz_id in biz_categories:
                score = 0
                for category in biz_categories[biz_id]:
                    score += user_prefs.get(category, 0)
                # ì‹ë‹¹ì˜ ì¹´í…Œê³ ë¦¬ ìˆ˜ë¡œ ì •ê·œí™”
                score /= max(1, len(biz_categories[biz_id]))
                scores_category[user_id][biz_id] = score
else:
    print("ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„°ë§ ë¹„í™œì„±í™”")


# ### 5. í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬í˜„

# In[8]:

print("\n[5] í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬í˜„ ì¤‘...")

# ê° ì¶”ì²œ ë°©ì‹ì˜ ê°€ì¤‘ì¹˜ ì„¤ì •
weights = {}
weights["content"] = 0.4
weights["cf"] = 0.2 if USE_CF else 0
weights["category"] = 0.2 if USE_CATEGORY else 0
weights["popularity"] = 0.2

# ê°€ì¤‘ì¹˜ ì •ê·œí™”
total = sum(weights.values())
for k in weights:
    weights[k] /= total

print(f"ì¶”ì²œ ê°€ì¤‘ì¹˜: {weights}")


# ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ
def get_popular_recommendations(user_id, exclude_items, k=TOP_N):
    recommendations = []
    for item in popular_biz_ids:
        if item not in exclude_items:
            recommendations.append(item)
            if len(recommendations) >= k:
                break
    return recommendations


# ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ
def get_content_recommendations(user_id, exclude_items, k=TOP_N):
    if user_id not in user_ids:
        return []

    user_idx = user_ids.index(user_id)
    user_score = scores_content[user_idx]
    ranked_idx = np.argsort(user_score)[::-1]

    recs = []
    for j in ranked_idx:
        bid = biz_ids[j]
        if bid not in exclude_items:
            recs.append(bid)
        if len(recs) == k:
            break
    return recs


# í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ
def get_cf_recommendations(user_id, exclude_items, k=TOP_N):
    if not USE_CF or user_id not in scores_cf:
        return []

    user_scores = scores_cf[user_id]
    sorted_items = sorted(user_scores.items(), key=lambda x: x[1], reverse=True)

    recs = []
    for bid, _ in sorted_items:
        if bid not in exclude_items:
            recs.append(bid)
        if len(recs) == k:
            break
    return recs


# ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì¶”ì²œ
def get_category_recommendations(user_id, exclude_items, k=TOP_N):
    if not USE_CATEGORY or user_id not in scores_category:
        return []

    user_scores = scores_category[user_id]
    sorted_items = sorted(user_scores.items(), key=lambda x: x[1], reverse=True)

    recs = []
    for bid, _ in sorted_items:
        if bid not in exclude_items:
            recs.append(bid)
        if len(recs) == k:
            break
    return recs


# #### ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ)

# In[9]:

print("í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ê³„ì‚° ì¤‘...")

user2seen = defaultdict(set)
for r in sampled_train_reviews:
    user2seen[r["user_id"]].add(r["business_id"])

# ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸
recommendations = {}
recommendations_content = {}  # ì½˜í…ì¸  ê¸°ë°˜ ê²°ê³¼ ì €ì¥ (ë¹„êµìš©)
recommendations_cf = {}  # í˜‘ì—… í•„í„°ë§ ê²°ê³¼ ì €ì¥ (ë¹„êµìš©)
recommendations_category = {}  # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê²°ê³¼ ì €ì¥ (ë¹„êµìš©)
recommendations_popular = {}  # ì¸ê¸°ë„ ê¸°ë°˜ ê²°ê³¼ ì €ì¥ (ë¹„êµìš©)

# ì¶”ê°€ kê°œì˜ ì¶”ì²œ í•­ëª©ì„ ê°€ì ¸ì™€ ì ìˆ˜ ë¶€ì—¬
EXTRA_K = 20

for user_id in tqdm(sampled_user_ids, desc="í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìƒì„± ì¤‘"):
    seen_items = user2seen[user_id]

    # ê° ë°©ì‹ë³„ ì¶”ì²œ ê²°ê³¼ (ìƒìœ„ EXTRA_Kê°œ)
    content_recs = get_content_recommendations(user_id, seen_items, EXTRA_K)
    cf_recs = get_cf_recommendations(user_id, seen_items, EXTRA_K)
    category_recs = get_category_recommendations(user_id, seen_items, EXTRA_K)
    popular_recs = get_popular_recommendations(user_id, seen_items, EXTRA_K)

    # ê¸°ì¡´ ê° ë°©ì‹ë³„ ì¶”ì²œ ì €ì¥ (ë¹„êµìš©, ìƒìœ„ TOP_Nê°œ)
    recommendations_content[user_id] = content_recs[:TOP_N]
    recommendations_cf[user_id] = cf_recs[:TOP_N]
    recommendations_category[user_id] = category_recs[:TOP_N]
    recommendations_popular[user_id] = popular_recs[:TOP_N]

    # ëª¨ë“  ì¶”ì²œ ì•„ì´í…œ ìˆ˜ì§‘
    all_items = set()
    for items in [content_recs, cf_recs, category_recs, popular_recs]:
        all_items.update(items)

    # ê° ì•„ì´í…œë³„ ê°€ì¤‘ì¹˜ í•©ì‚° ì ìˆ˜ ê³„ì‚°
    biz_score_map = {}
    for item in all_items:
        score = 0
        # ì½˜í…ì¸  ê¸°ë°˜ ì ìˆ˜
        if item in content_recs:
            score += weights["content"] * (1 - content_recs.index(item) / EXTRA_K)
        # í˜‘ì—… í•„í„°ë§ ì ìˆ˜
        if item in cf_recs:
            score += weights["cf"] * (1 - cf_recs.index(item) / EXTRA_K)
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì ìˆ˜
        if item in category_recs:
            score += weights["category"] * (1 - category_recs.index(item) / EXTRA_K)
        # ì¸ê¸°ë„ ê¸°ë°˜ ì ìˆ˜
        if item in popular_recs:
            score += weights["popularity"] * (1 - popular_recs.index(item) / EXTRA_K)

        biz_score_map[item] = score

    # ì ìˆ˜ì— ë”°ë¼ ì •ë ¬í•˜ì—¬ ìµœì¢… ì¶”ì²œ ìƒì„±
    hybrid_recs = sorted(biz_score_map.items(), key=lambda x: x[1], reverse=True)[
        :TOP_N
    ]
    recommendations[user_id] = [item[0] for item in hybrid_recs]


# #### í‰ê°€: Ground Truth ìƒì„±

# In[10]:

print("\ní‰ê°€ ì¤€ë¹„ ì¤‘...")

ground_truth = defaultdict(set)
for r in test_reviews:
    if r["user_id"] in sampled_user_ids:  # ìƒ˜í”Œë§ëœ ìœ ì €ë§Œ í‰ê°€
        ground_truth[r["user_id"]].add(r["business_id"])


# #### í‰ê°€ í•¨ìˆ˜ ì •ì˜

# In[11]:


def evaluate_recommendations(rec_dict, gt_dict, name=""):
    common_users = set(rec_dict.keys()) & set(gt_dict.keys())
    precision_list = []
    hit_rate_list = []
    ndcg_list = []

    for uid in common_users:
        # ì¶”ì²œ ë¦¬ìŠ¤íŠ¸
        pred = rec_dict[uid]
        pred_set = set(pred)
        # ì‹¤ì œ ë°©ë¬¸í•œ ì‹ë‹¹ë“¤
        actual = gt_dict[uid]

        # Precision@K
        hit = len(pred_set & actual)
        precision = hit / TOP_N
        precision_list.append(precision)

        # Hit Rate@K
        hit_rate = 1 if hit > 0 else 0
        hit_rate_list.append(hit_rate)

        # NDCG@K
        dcg = 0
        for i, item in enumerate(pred):
            if item in actual:
                dcg += 1.0 / np.log2(i + 2)

        idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(actual), TOP_N)))
        ndcg = dcg / idcg if idcg > 0 else 0
        ndcg_list.append(ndcg)

    print(f"ğŸ“Š {name} ê²°ê³¼ (ì´ {len(common_users)}ëª… í‰ê°€):")
    print(f"ğŸ¯ Precision@{TOP_N}: {np.mean(precision_list):.4f}")
    print(f"ğŸ¯ Hit Rate@{TOP_N}: {np.mean(hit_rate_list):.4f}")
    print(f"ğŸ¯ NDCG@{TOP_N}: {np.mean(ndcg_list):.4f}")
    print("-" * 50)

    return {
        "precision": np.mean(precision_list),
        "hit_rate": np.mean(hit_rate_list),
        "ndcg": np.mean(ndcg_list),
    }


# #### ê° ë°©ì‹ë³„ ì„±ëŠ¥ í‰ê°€

# In[12]:

results = {}

print("\n===== ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ =====\n")

# ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ í‰ê°€
results["popularity"] = evaluate_recommendations(
    recommendations_popular, ground_truth, "ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œ"
)

# ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ í‰ê°€
results["content"] = evaluate_recommendations(
    recommendations_content, ground_truth, "ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ"
)

# í˜‘ì—… í•„í„°ë§ ì¶”ì²œ í‰ê°€ (í™œì„±í™”ëœ ê²½ìš°)
if USE_CF:
    results["cf"] = evaluate_recommendations(
        recommendations_cf, ground_truth, "í˜‘ì—… í•„í„°ë§ ì¶”ì²œ"
    )

# ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì¶”ì²œ í‰ê°€ (í™œì„±í™”ëœ ê²½ìš°)
if USE_CATEGORY:
    results["category"] = evaluate_recommendations(
        recommendations_category, ground_truth, "ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì¶”ì²œ"
    )

# í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ í‰ê°€
results["hybrid"] = evaluate_recommendations(
    recommendations, ground_truth, "í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ"
)

# ìµœê³  ì„±ëŠ¥ ë°©ì‹ ì¶œë ¥
best_method = max(results.items(), key=lambda x: x[1]["hit_rate"])
print(
    f"ğŸ† ìµœê³  ì„±ëŠ¥ ë°©ì‹: {best_method[0]}, Hit Rate: {best_method[1]['hit_rate']:.4f}"
)
